{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunaeee/upstage/blob/main/claude_fewshot_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jnkdm52w120u"
      },
      "outputs": [],
      "source": [
        "# 0. 필요한 디렉토리 생성\n",
        "from pathlib import Path\n",
        "Path(\"./logs\").mkdir(exist_ok=True)\n",
        "Path(\"./output\").mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXkM_i7Y120w"
      },
      "outputs": [],
      "source": [
        "pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CGSsuu1120x"
      },
      "outputs": [],
      "source": [
        "# 1. 필요한 라이브러리 임포트\n",
        "import pandas as pd\n",
        "from anthropic import Anthropic  # OpenAI 대신 Anthropic 임포트\n",
        "from rouge_score import rouge_scorer\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import json\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHKK5LP4120x"
      },
      "outputs": [],
      "source": [
        "# 2. 로깅 설정\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(f\"./logs/summarizer_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65Cl8j1j120y"
      },
      "outputs": [],
      "source": [
        "# 3. Claude API 설정\n",
        "anthropic = Anthropic(api_key='...')  # 여기에 Claude API 키를 넣으세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlt6khzt120y"
      },
      "outputs": [],
      "source": [
        "# 4. 시스템 프롬프트 정의\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rarDoBoO120y"
      },
      "outputs": [],
      "source": [
        "# 5. Few-shot 예시 정의\n",
        "FEW_SHOT_EXAMPLES = \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn4a5U2-120y"
      },
      "outputs": [],
      "source": [
        "# 5. 데이터 로딩 함수\n",
        "def load_data(file_path):\n",
        "    try:\n",
        "        return pd.read_csv(file_path)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading data from {file_path}: {e}\")\n",
        "        raise\n",
        "\n",
        "# 데이터 로드\n",
        "train_data = load_data('../data/train.csv')\n",
        "dev_data = load_data('../data/dev.csv')\n",
        "test_data = load_data('../data/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ-5J5E3120z"
      },
      "outputs": [],
      "source": [
        "# 6. 데이터 전처리: 필요한 컬럼만 선택\n",
        "train_dialogues = train_data['dialogue'].tolist()\n",
        "train_summaries = train_data['summary'].tolist()\n",
        "dev_dialogues = dev_data['dialogue'].tolist()\n",
        "dev_summaries = dev_data['summary'].tolist()\n",
        "test_dialogues = test_data['dialogue'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4VFFeGL120z"
      },
      "outputs": [],
      "source": [
        "# Claude API를 사용하여 요약 생성\n",
        "def generate_summary_with_claude(dialogue, index=None):\n",
        "    try:\n",
        "        if index is not None:\n",
        "            logger.info(f\"Processing index: {index}\")\n",
        "\n",
        "        response = anthropic.messages.create(\n",
        "            model=\"claude-3-opus-20240229\",\n",
        "            system=SYSTEM_PROMPT,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"다음은 대화 요약의 예시입니다:\\n{FEW_SHOT_EXAMPLES}\\n\\n\"\n",
        "                              f\"이제 다음 대화를 위 예시들처럼 요약해주세요:\\n{dialogue}\"\n",
        "                }\n",
        "            ],\n",
        "            max_tokens=150,\n",
        "            temperature=0.5\n",
        "        )\n",
        "        summary = response.content[0].text\n",
        "        logger.info(f\"Summary for index {index}: {summary}\")\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating summary: {e}\")\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHlDCrqV120z"
      },
      "outputs": [],
      "source": [
        "# 8. ROUGE 점수 계산 [이전과 동일]\n",
        "def calculate_rouge_score(predictions, references):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    rouge_results = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        if pred and ref:\n",
        "            scores = scorer.score(ref, pred)\n",
        "            for metric in rouge_results:\n",
        "                rouge_results[metric].append(scores[metric].fmeasure)\n",
        "\n",
        "    rouge_avg = {key: sum(value) / len(value) if value else 0\n",
        "                for key, value in rouge_results.items()}\n",
        "    return rouge_avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNpnUJxx120z"
      },
      "outputs": [],
      "source": [
        "# 9. 개발 데이터 평가\n",
        "def evaluate_on_dev():\n",
        "    logger.info(\"Starting evaluation on dev set...\")\n",
        "    predictions = []\n",
        "\n",
        "    for idx, dialogue in enumerate(tqdm(dev_dialogues, desc=\"Evaluating on dev set\")):\n",
        "        summary = generate_summary_with_claude(dialogue, idx)  # 함수명 변경\n",
        "        predictions.append(summary)\n",
        "\n",
        "    rouge_scores = calculate_rouge_score(predictions, dev_summaries)\n",
        "    logger.info(f\"ROUGE Scores on Dev Set: {rouge_scores}\")\n",
        "    return rouge_scores, predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5xaa0e51200"
      },
      "outputs": [],
      "source": [
        "# 10. 테스트 데이터 요약 생성\n",
        "def generate_summaries_for_test():\n",
        "    logger.info(\"Generating summaries for test set...\")\n",
        "    test_summaries = []\n",
        "\n",
        "    for idx, dialogue in enumerate(tqdm(test_dialogues, desc=\"Generating summaries for test set\")):\n",
        "        summary = generate_summary_with_claude(dialogue, idx)  # 함수명 변경\n",
        "        test_summaries.append(summary)\n",
        "\n",
        "    return test_summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCYVf-Sb1200"
      },
      "outputs": [],
      "source": [
        "# 메인 실행 부분 [이전과 동일]\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # 개발 데이터 평가\n",
        "        dev_scores, dev_predictions = evaluate_on_dev()\n",
        "\n",
        "        # 결과 저장\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "        # 개발 셋 결과 저장\n",
        "        dev_results_df = pd.DataFrame({\n",
        "            'dialogue': dev_dialogues,\n",
        "            'reference_summary': dev_summaries,\n",
        "            'generated_summary': dev_predictions\n",
        "        })\n",
        "\n",
        "        # 테스트 데이터 요약 생성\n",
        "        test_summaries = generate_summaries_for_test()\n",
        "\n",
        "        # 테스트 결과 저장\n",
        "        test_results_df = pd.DataFrame({\n",
        "            'fname': test_data['fname'],\n",
        "            'dialogue': test_data['dialogue'],\n",
        "            'summary': test_summaries\n",
        "        })\n",
        "\n",
        "        dev_results_df.to_csv(f'./output/dev_results_{timestamp}.csv', index=False)\n",
        "        test_results_df.to_csv(f'./output/test_results_{timestamp}.csv', index=False)\n",
        "\n",
        "        # 점수 저장\n",
        "        with open(f'./output/dev_scores_{timestamp}.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(dev_scores, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        logger.info(\"All results have been saved to output directory\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Pipeline failed: {e}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv3_P6Os1200"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}